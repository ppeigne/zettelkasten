Previous: [[]]
Source: [[]]
Consider: [[]]
Tags: 
______________

### Investigating claims on "data induced" emergent capabilities

Does the synthetic dataset from Xie et al. (2022) [[An Explanation of In-context Learning as Implicit Bayesian Inference]] displays the properties mentioned by Chan et al. (2022) [[Data Distributional Properties Drive Emergent In-Context Learning in Transformers]] (burstiness, large number of occurring classes + dynamic meaning) ? 

And conversely, does the dataset from Chan et al (2022) displays the properties of the synthetic dataset (i.e. "long range coherence").

-> If yes: why were Chan et al.  not able to generate emergent in-prompt learning from RNNs?


### Studying the training dynamics on network structure  using synthetic data 
Training on the small synthetic dataset allows to run complete training at affordable costs (few hours). We can therefore explore some of the suggestions made in [[Emergent Structures and Training Dynamics in Large Language Models]] Teehan et al (2022): understanding the change in the network structure over training, experimenting on network structure.

#### Monitoring internals at emergence time
By doing such training from scratch we could observe the internals of the model while being trained, especially at the emergence of in-prompt learning abilities.

-> For instance, monitor the norm/parameter growth and compare it with the results from  Merill et al. (2021) or Thilak et al. (2022).

#### Experimenting with induced modularity 
We can try to train the transformer with methods dedicated to create more modular networks and observe the impact on emergent in-prompt learning. 

