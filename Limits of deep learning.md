# Limits of deep learning

Deep learning algorithms look very much alike [[system 1]] neurological processes. They are very effective to detect patterns but are not good to produce and manipulate abstractions like [[system 2]] processes.

The ??? theorem states that an deep network can **approximate** any mathematical functions if it is deep enough. 

However **a lot of cognitive processes are not based on approximation** such as mathematical operations. 
It is quite difficult (impossible ?) to make a deep learning algorithm learn to make additions perfectly. 

Following (and even better crating) procedure is not an approximation process. This process seems of first importance in the ability to develop intelligence.



