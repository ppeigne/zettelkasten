Previous: [[]]
Source: [[Insights into Pre-training via Simpler Synthetic Tasks]]
Consider: [[Effects of Parameter Norm Growth During Transformer Training - Inductive Bias from Gradient Descent]]
Tags: #parameter_statistics, #saturation
______________

Using parameter statistics from a pre-trained model as model initialization allows to obtain non-negligible performances (39%). 
-> How much saturated are the layers? Can we get better performance by forcing the initialization to only rely on statistics but also on saturation rate?