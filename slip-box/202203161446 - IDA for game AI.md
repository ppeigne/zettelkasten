Previous: [[]]
Source: [[Supervising strong learners by amplifying weak experts (Christiano et al., 2018)]]
Consider: [[]]
Tags: #ida #game_ai
______________

IDA applied to self play could reduce the training steps. 
-> Should imply variations in the answers/moves (if no variations multiples $X$ will play exactly the same)

Variation could come from:
- initial state variation (e.g the 'sub-problems' $p_n$ are generated as moves from the current state of the board). Calling $X(p_n)$ gives the best moves from the state $p_n$, and $\text{Amplify}(X)$ consists of a selection (using an internal heuristic) of the best moves among the $p$ 
- players mutations: after each train of $X$, the college is build by mutations of $X$. 