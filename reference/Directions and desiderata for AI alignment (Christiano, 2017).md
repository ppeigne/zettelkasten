Source: https://ai-alignment.com/directions-and-desiderata-for-ai-control-b60fca0da8f4
Consider: [[]]
Tags: #reliability #robustness #oversight #reward_learning #amplification #deliberation
______________

Three research directions:
1. **Reliability and robustness**: the agent stay safe out-of-distribution (and even in an adversarial environment)
-> Adversarial training
-> Ensembling and consensus
-> (Learning the right model: MIRI)

2. **Oversight and reward learning**: the agent learn to do what we intend it to do as an (robust) objective
-> IRL
-> Human feedback

3. **Deliberation and amplification**: stay aligned while amplified
-> IRL (hard mode)
-> Iterated amplification
-> IRL for cognition (Ought)

Desiderata:
1. Secure: stay safe even confronted to adversarial environment
2. Competitive: stay competitive compared to other solutions not focused on safety
3. Scalable: stay aligned even when the underlying algo improve by a lot (more data, more compute etc.).

