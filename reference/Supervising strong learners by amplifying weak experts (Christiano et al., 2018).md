Source: https://arxiv.org/pdf/1810.08575.pdf
Consider: [[]]
Tags: #amplification #distillation #ida #weak_expert
______________

# Supervising strong learners by amplifying weak experts


### Problem of training signal for superhuman tasks
Training signal (evaluates how well the ML system is doing at a given task).
- algorithmic training signal (trivial) : generated by an algo
- pb: alg. training sig are missing for most useful tasks. -> Rely on human training signal. 
- pb: complex task "beyond human scale" cannot get human training sign. Because cannot be judged by a single human directly (possibly on a very long run which too slow to learn from) 

### The strategy 
$\text{Amplify}(X)$: multiples instances of $X$ working on an original problem $P$ divided into simpler sub-problems $p_n$
 
The point is to train $X$ on the I/O of $\text{Amplify}(X)$.
Each time $X$ become better so do $\text{Amplify}(X)$.

Therefore a college of $X$ can be used as training signal to train $X$ itself.

The division part is only a part of the 'college'. 
-> $X$ learns to answers **like** $\text{Amplify}(X)$ directly from it's I/O. $X$ execution does not include explicit call to a division algorithm. $X$ can develop such an algorithm internally, but it will be a mesa optimization task.  

