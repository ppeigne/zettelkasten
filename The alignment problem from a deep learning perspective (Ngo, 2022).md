Source: 
Consider: [[]]
Tags: 
______________

# Claim
### 1. learning to plan toward achieving a range of goals
reward mispecification problem

"Policies will develop sophisticated internal representations of a range of outcomes which are correlated with higher reward on multiple tasks, and learn to make plan to achieve them."



### 2. pursuing goals in a situationally-aware way
deceptive alignment problem

"Once policies can reason about their training processes and deployment contexts, they'll learn to deceptively pursue misaligned goals while still getting high training reward."

### 3. generalizing goals beyond human supervision
goal misgeneralization problem

"Policies which are too capable for humans to effectively supervise will generalize towards taking actions which give them more power over the world, rather than following human intentions."

# Key takeaways